{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.layers import Input, Conv2D, Dropout, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "import matplotlib.pylab as plt\n",
    "import scipy.linalg\n",
    "from sklearn.cluster import k_means\n",
    "from sklearn.cluster import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imutils import paths\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 50\n",
    "imsize = 128\n",
    "\n",
    "# input image dimensions\n",
    "img_x, img_y = imsize, imsize\n",
    "input_shape = (img_x, img_y,3)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 550 images belonging to 10 classes.\n",
      "Found 100 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "#ImageDataGenerator to generate batches of images\n",
    "#add: zca_whitening = True,\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',\n",
    "        target_size=(imsize, imsize),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/validation',\n",
    "        target_size=(imsize, imsize),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(train_datagen.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10005': 0,\n",
       " '10026': 1,\n",
       " '10028': 2,\n",
       " '10033': 3,\n",
       " '10045': 4,\n",
       " '1005': 5,\n",
       " '10067': 6,\n",
       " '1031': 7,\n",
       " '1046': 8,\n",
       " '1054': 9}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_36 (Conv2D)           (None, 124, 124, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 58, 58, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 53824)             0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 100)               5382500   \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 5,437,206\n",
      "Trainable params: 5,437,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "184/184 [==============================] - 65s 352ms/step - loss: 2.2781 - acc: 0.1359 - val_loss: 2.1935 - val_acc: 0.1900\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 64s 349ms/step - loss: 2.1311 - acc: 0.2373 - val_loss: 1.9456 - val_acc: 0.3400\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 63s 341ms/step - loss: 1.9480 - acc: 0.3442 - val_loss: 1.9407 - val_acc: 0.2600\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 64s 346ms/step - loss: 1.6997 - acc: 0.4167 - val_loss: 1.6275 - val_acc: 0.4400\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 61s 333ms/step - loss: 1.4808 - acc: 0.5000 - val_loss: 1.7145 - val_acc: 0.4600\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 63s 341ms/step - loss: 1.2973 - acc: 0.5996 - val_loss: 1.5894 - val_acc: 0.4800\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 65s 355ms/step - loss: 0.9206 - acc: 0.7083 - val_loss: 1.5761 - val_acc: 0.5100\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 62s 336ms/step - loss: 0.6135 - acc: 0.8098 - val_loss: 1.7790 - val_acc: 0.5200\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 63s 340ms/step - loss: 0.4102 - acc: 0.8750 - val_loss: 1.9993 - val_acc: 0.4400\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 61s 329ms/step - loss: 0.2044 - acc: 0.9330 - val_loss: 2.5896 - val_acc: 0.4900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f8826e588>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=validation_generator,\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_generator.classes\n",
    "yval = validation_generator.classes\n",
    "\n",
    "yp = model.predict_generator(train_generator)\n",
    "yp = [np.argmax(x) for x in yp]\n",
    "ypval = model.predict_generator(validation_generator)\n",
    "ypval = [np.argmax(x) for x in ypval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([yval,ypval])\n",
    "df = df.transpose()\n",
    "df.columns =['t','p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#modifying probabilities so that they sum up to 1\n",
    "def softmax(ftr):\n",
    "    print('compute softmax probabilities')\n",
    "    num, dim = ftr.shape[0], ftr.shape[1]\n",
    "    print('num %d dim %d' % (num, dim))\n",
    "    prob = np.zeros((num, dim), dtype=np.single)\n",
    "    for i in range(num):\n",
    "        max_val = np.max(ftr[i, :])\n",
    "        row = ftr[i, :] - max_val\n",
    "        exp_val = np.exp(row)\n",
    "        prob[i, :] = exp_val / np.sum(exp_val)\n",
    "    return prob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n"
     ]
    }
   ],
   "source": [
    "#TODO: automate\n",
    "num_values = len(train_datagen.classes)\n",
    "\n",
    "conf_mat = np.zeros((num_classes,num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute softmax probabilities\n",
      "num 100 dim 10\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Hardcoding 100-class probabilities for validation images .\n",
    "'''\n",
    "#class_prob = [14/59,16/59,5/59,14/59,10/59]\n",
    "class_prob = [0.1]*num_classes\n",
    "val_prob = np.zeros((num_values,num_classes))\n",
    "\n",
    "for i in range(num_values):\n",
    "    for j in range(num_classes):\n",
    "        val_prob[i][j]=class_prob[j]\n",
    "val_prob=softmax(val_prob)\n",
    "#print(val_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   t  p\n",
       "0  0  1\n",
       "1  0  5\n",
       "2  0  5\n",
       "3  0  7\n",
       "4  0  8"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(df.shape[0]):\n",
    "    t = df.loc[i]['t']\n",
    "    p = df.loc[i]['p']\n",
    "    #print(conf_mat)\n",
    "    conf_mat[t][p] = conf_mat[t][p] +1\n",
    "    #print(conf_mat)\n",
    "for i in range(num_classes):\n",
    "    conf_mat[i] = conf_mat[i]/sum(conf_mat[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1 0.1 0.  0.  0.  0.4 0.1 0.1 0.2 0. ]\n",
      " [0.  0.1 0.3 0.1 0.  0.2 0.  0.2 0.1 0. ]\n",
      " [0.1 0.  0.  0.  0.2 0.3 0.  0.2 0.1 0.1]\n",
      " [0.2 0.  0.  0.2 0.2 0.3 0.  0.1 0.  0. ]\n",
      " [0.3 0.  0.  0.1 0.1 0.4 0.  0.1 0.  0. ]\n",
      " [0.1 0.  0.  0.2 0.1 0.3 0.1 0.1 0.  0.1]\n",
      " [0.1 0.  0.  0.1 0.2 0.3 0.2 0.1 0.  0. ]\n",
      " [0.  0.  0.1 0.  0.2 0.3 0.2 0.1 0.1 0. ]\n",
      " [0.  0.2 0.  0.  0.3 0.2 0.1 0.  0.  0.2]\n",
      " [0.1 0.2 0.1 0.  0.1 0.3 0.1 0.  0.  0.1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22f88349710>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(conf_mat)\n",
    "plt.imshow(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22f88332438>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist_mat = 1 - conf_mat\n",
    "'''set diagonal elements to 0'''\n",
    "dist_mat[range(num_classes),range(num_classes)]=0\n",
    "dist_mat = 0.5 * (dist_mat + dist_mat.T)\n",
    "plt.figure()\n",
    "plt.title('distance matrix on validation set')\n",
    "plt.imshow(dist_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.31622777 -0.31622777 -0.31622777 -0.31622777 -0.31622777 -0.31622777\n",
      " -0.31622777 -0.31622777 -0.31622777 -0.31622777]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22f06a7b3c8>]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Laplacian eigenmap dimensionality reduction\n",
    "construct adjacency graph W (symmetric) using k-NN'''\n",
    "W=np.zeros((num_classes,num_classes))\n",
    "\n",
    "#TODO: hyper-parameter optimization\n",
    "k_nn, t, dim = 3, 0.9, 4\n",
    "\n",
    "for i in range(num_classes):\n",
    "    idx=np.argsort(dist_mat[i,:])[1:k_nn+1]\n",
    "    W[i,idx]=np.exp(-dist_mat[i,idx] / t)\n",
    "    W[idx,i]=W[i,idx]\n",
    "D=np.zeros(W.shape)\n",
    "for i in range(num_classes):\n",
    "    D[i,i]=np.sum(W[i,:])\n",
    "L=D-W\n",
    "eig_val,eig_vec=scipy.linalg.eig(L,D)\n",
    "ftr=eig_vec[:,1:dim+1]\n",
    "print(eig_vec[:,0]) # the 1st eigenvector should be all ones\n",
    "eigval_cumsum = np.cumsum(np.real(eig_val))\n",
    "plt.plot(eigval_cumsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 clusters\n"
     ]
    }
   ],
   "source": [
    "#TODO: hyperparameter optimization\n",
    "affinity_propagation_cluster = AffinityPropagation(damping=0.75, max_iter=15000, convergence_iter=50, copy=True) \n",
    "cluster_labels = affinity_propagation_cluster.fit_predict(ftr)\n",
    "unique_cluster_label = np.unique(cluster_labels)\n",
    "n_cluster = unique_cluster_label.shape[0]\n",
    "cluster_members=[None]*n_cluster\n",
    "print ('%d clusters' % n_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 0 size 3 \n",
      "1,\n",
      "8,\n",
      "9,\n",
      " \n",
      "cluster 1 size 7 \n",
      "0,\n",
      "2,\n",
      "3,\n",
      "4,\n",
      "5,\n",
      "6,\n",
      "7,\n",
      " \n",
      "[[1, 8, 9], [0, 2, 3, 4, 5, 6, 7]]\n"
     ]
    }
   ],
   "source": [
    "label_names=range(num_classes)\n",
    "for i in range(n_cluster):\n",
    "    idx = np.nonzero(cluster_labels == unique_cluster_label[i])[0]\n",
    "    cluster_members[i]=list(idx)\n",
    "    print ('cluster %d size %d ' % (i, len(idx)))\n",
    "    for j in range(len(idx)):\n",
    "        print ('%s,' % label_names[idx[j]],)\n",
    "    print (' ')\n",
    "print(cluster_members)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2cmap = {}\n",
    "for coarse in range(len(cluster_members)):\n",
    "    for fine in cluster_members[coarse]:\n",
    "        f2cmap[fine] = coarse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_fine = train_generator.classes\n",
    "train_coarse = [f2cmap[c] for c in train_fine]\n",
    "val_fine = validation_generator.classes\n",
    "val_coarse = [f2cmap[c] for c in val_fine]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# The number of coarse categories\n",
    "coarse_categories = n_cluster\n",
    "# The number of fine categories\n",
    "fine_categories = num_classes\n",
    "\n",
    "print(coarse_categories)\n",
    "print(fine_categories)\n",
    "\n",
    "# fine2coarse = np.zeros((fine_categories,coarse_categories))\n",
    "# for i in range(coarse_categories):\n",
    "#     for j in cluster_members[i]:\n",
    "#         fine2coarse[j,i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#single classifier training (shared)\n",
    "in_layer = Input(shape=input_shape, dtype='float32', name='main_input')\n",
    "\n",
    "net = Conv2D(384, 3, strides=1, padding='same', activation='elu')(in_layer)\n",
    "net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "\n",
    "net = Conv2D(384, 1, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(384, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(640, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(640, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Dropout(.2)(net)\n",
    "net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "\n",
    "net = Conv2D(640, 1, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(768, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(768, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(768, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Dropout(.3)(net)\n",
    "net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "\n",
    "net = Conv2D(768, 1, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(896, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(896, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Dropout(.4)(net)\n",
    "net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "\n",
    "net = Conv2D(896, 3, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(1024, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(1024, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Dropout(.5)(net)\n",
    "net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "\n",
    "net = Conv2D(1024, 1, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(1152, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Dropout(.6)(net)\n",
    "net = MaxPooling2D((2, 2), padding='same')(net)\n",
    "\n",
    "net = Flatten()(net)\n",
    "net = Dense(1152, activation='elu')(net)\n",
    "net = Dense(fine_categories, activation='softmax')(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=in_layer,outputs=net)\n",
    "sgd_coarse = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer= sgd_coarse, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Devanshi\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:975: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "184/184 [==============================] - 2073s 11s/step - loss: 14.5121 - acc: 0.0996 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 2/2\n",
      "184/184 [==============================] - 2206s 12s/step - loss: 14.5121 - acc: 0.0996 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 3/3\n",
      "184/184 [==============================] - 2142s 12s/step - loss: 14.5121 - acc: 0.0996 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 4/4\n",
      "184/184 [==============================] - 2418s 13s/step - loss: 14.5121 - acc: 0.0996 - val_loss: 14.5063 - val_acc: 0.1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "index= 0\n",
    "step = 5\n",
    "stop = 30\n",
    "\n",
    "if not os.path.exists(\"data/models\"):\n",
    "        os.makedirs(\"data/models\")\n",
    "        \n",
    "while index < stop:\n",
    "    model.fit_generator(train_generator,\n",
    "          epochs=index+step,\n",
    "          verbose=1, initial_epoch=index,\n",
    "          validation_data=validation_generator,\n",
    "          )\n",
    "    index += step\n",
    "    model.save_weights('data/models/model_coarse'+str(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.load_weights('data/models/model_coarse'+str(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_fine = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(model.layers)):\n",
    "    model.layers[i].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fine-tuning for coarse classifier\n",
    "net = Conv2D(1024, 1, strides=1, padding='same', activation='elu')(model.layers[-8].output)\n",
    "net = Conv2D(1152, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Dropout(.6)(net)\n",
    "net = MaxPooling2D((2, 2), padding='same')(net)\n",
    "\n",
    "net = Flatten()(net)\n",
    "net = Dense(1152, activation='elu')(net)\n",
    "out_coarse = Dense(coarse_categories, activation='softmax')(net)\n",
    "\n",
    "model_c = Model(inputs=in_layer,outputs=out_coarse)\n",
    "model_c.compile(optimizer= sgd_coarse, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "for i in range(len(model_c.layers)-1):\n",
    "    model_c.layers[i].set_weights(model.layers[i].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_c.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'10026': 1, '1031': 7, '10033': 3, '1005': 5, '10005': 0, '10028': 2, '10067': 6, '1054': 9, '1046': 8, '10045': 4}\n"
     ]
    }
   ],
   "source": [
    "#generating directory structure for coarse categories\n",
    "#we will have all fine categories as directories within each coarse category i.e most will be empty\n",
    "print(train_generator.class_indices)\n",
    "     \n",
    "traindict = train_generator.class_indices\n",
    "traindest = \"data/ctrain\"\n",
    "trainsrc = \"data/train\"\n",
    "valdict = validation_generator.class_indices\n",
    "valdest = \"data/cvalidation\"\n",
    "valsrc = \"data/validation\"\n",
    "\n",
    "for c in range(coarse_categories):\n",
    "    if not os.path.exists(traindest+\"/\"+str(c)):\n",
    "        os.makedirs(traindest+\"/\"+str(c))\n",
    "    if not os.path.exists(valdest+\"/\"+str(c)):\n",
    "        os.makedirs(valdest+\"/\"+str(c))\n",
    "    for key in traindict:\n",
    "        if not os.path.exists(traindest+\"/\"+str(c)+\"/\"+key):\n",
    "            os.makedirs(traindest+\"/\"+str(c)+\"/\"+key)\n",
    "        if not os.path.exists(valdest+\"/\"+str(c)+\"/\"+key):\n",
    "            os.makedirs(valdest+\"/\"+str(c)+\"/\"+key)\n",
    "\n",
    "for key in traindict:\n",
    "    val = traindict[key]\n",
    "    c = f2cmap[val]\n",
    "    os.system('cp '+ trainsrc+key +\"/* \"+ traindest+\"/\"+ str(c)+\"/\"+key)\n",
    "    \n",
    "for key in valdict:\n",
    "    val = valdict[key]\n",
    "    c = f2cmap[val]\n",
    "    os.system('cp '+ valsrc+key +\"/* \"+ valdest+\"/\"+ str(c)+\"/\"+key)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 550 images belonging to 2 classes.\n",
      "Found 100 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "ctrain_generator = train_datagen.flow_from_directory(\n",
    "        'data/ctrain',\n",
    "        target_size=(imsize, imsize),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "cvalidation_generator = test_datagen.flow_from_directory(\n",
    "        'data/cvalidation',\n",
    "        target_size=(imsize, imsize),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n",
      "184/184 [==============================] - 1204s 7s/step - loss: 11.2420 - acc: 0.3025 - val_loss: 11.2827 - val_acc: 0.3000\n",
      "Epoch 6/6\n",
      "184/184 [==============================] - 1178s 6s/step - loss: 11.3001 - acc: 0.2989 - val_loss: 11.2827 - val_acc: 0.3000\n",
      "Epoch 7/7\n",
      "184/184 [==============================] - 1252s 7s/step - loss: 11.3001 - acc: 0.2989 - val_loss: 11.2827 - val_acc: 0.3000\n"
     ]
    }
   ],
   "source": [
    "index = 30\n",
    "step = 5\n",
    "stop = 50\n",
    "\n",
    "while index < stop:\n",
    "    model_c.fit_generator(ctrain_generator,\n",
    "          epochs=index+step,\n",
    "          verbose=1, initial_epoch=index,\n",
    "          validation_data = cvalidation_generator\n",
    "          )\n",
    "    index += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/8\n",
      "184/184 [==============================] - 925s 5s/step - loss: 11.2420 - acc: 0.3025 - val_loss: 11.2827 - val_acc: 0.3000\n",
      "Epoch 9/9\n",
      "184/184 [==============================] - 798s 4s/step - loss: 11.3001 - acc: 0.2989 - val_loss: 11.2827 - val_acc: 0.3000\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 844s 5s/step - loss: 11.3001 - acc: 0.2989 - val_loss: 11.2827 - val_acc: 0.3000\n"
     ]
    }
   ],
   "source": [
    "model_c.compile(optimizer=sgd_fine, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "stop = 80\n",
    "\n",
    "while index < stop:\n",
    "    model_c.fit_generator(ctrain_generator,\n",
    "          epochs=index+step,\n",
    "          verbose=1, initial_epoch=index,\n",
    "          validation_data = cvalidation_generator\n",
    "          )\n",
    "    index += step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables:\n",
    "y, yval, yp, ypval : true and predicted labels for train and validation\n",
    "train_coarse, train_fine, val_coarse,val_fine : coarse and fine labels for train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#constructing fine classifiers\n",
    "def fine_model():\n",
    "    net = Conv2D(1024, 1, strides=1, padding='same', activation='elu')(model.layers[-8].output)\n",
    "    net = Conv2D(1152, 2, strides=1, padding='same', activation='elu')(net)\n",
    "    net = Dropout(.6)(net)\n",
    "    net = MaxPooling2D((2, 2), padding='same')(net)\n",
    "\n",
    "    net = Flatten()(net)\n",
    "    net = Dense(1152, activation='elu')(net)\n",
    "    out_fine = Dense(fine_categories, activation='softmax')(net)\n",
    "    model_fine = Model(inputs=in_layer,outputs=out_fine)\n",
    "    model_fine.compile(optimizer= sgd_coarse,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    for i in range(len(model_fine.layers)-1):\n",
    "        model_fine.layers[i].set_weights(model.layers[i].get_weights())\n",
    "    return model_fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fine_models = {'models' : [{} for i in range(coarse_categories)], 'yhf' : [{} for i in range(coarse_categories)]}\n",
    "for i in range(coarse_categories):\n",
    "    model_i = fine_model()\n",
    "    fine_models['models'][i] = model_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_error(y,yh):\n",
    "    # Threshold \n",
    "    yht = np.zeros(np.shape(yh))\n",
    "    #here, 1 denotes axis=column\n",
    "    yht[np.arange(len(yh)), yh.argmax(1)] = 1\n",
    "    # Evaluate Error\n",
    "    error = np.count_nonzero(np.count_nonzero(y-yht,1))/len(y)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 165 images belonging to 10 classes.\n",
      "Found 30 images belonging to 10 classes.\n",
      "Found 385 images belonging to 10 classes.\n",
      "Found 70 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "#creating generators for fine classifiers\n",
    "traingenlist = []\n",
    "valgenlist = []\n",
    "for i in range(coarse_categories):\n",
    "    tgen = train_datagen.flow_from_directory(\n",
    "            'data/ctrain/'+str(i),\n",
    "            target_size=(imsize, imsize),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "    vgen = test_datagen.flow_from_directory(\n",
    "            'data/cvalidation/'+str(i),\n",
    "            target_size=(imsize, imsize),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "    traingenlist.append(tgen)\n",
    "    valgenlist.append(vgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 8, 9]\n",
      "Epoch 1/5\n",
      "55/55 [==============================] - 232s 4s/step - loss: 11.8199 - acc: 0.2667 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 2/5\n",
      "55/55 [==============================] - 245s 4s/step - loss: 10.7454 - acc: 0.3333 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 3/5\n",
      "55/55 [==============================] - 234s 4s/step - loss: 10.7454 - acc: 0.3333 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 4/5\n",
      "55/55 [==============================] - 236s 4s/step - loss: 10.7454 - acc: 0.3333 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 5/5\n",
      "55/55 [==============================] - 236s 4s/step - loss: 10.7454 - acc: 0.3333 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 235s 4s/step - loss: 10.7454 - acc: 0.3333 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 246s 4s/step - loss: 10.7454 - acc: 0.3333 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 256s 5s/step - loss: 10.7454 - acc: 0.3333 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 252s 5s/step - loss: 10.7454 - acc: 0.3333 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 253s 5s/step - loss: 10.7454 - acc: 0.3333 - val_loss: 10.7454 - val_acc: 0.3333\n",
      "Fine Classifier 0 Error: \n",
      "[0, 2, 3, 4, 5, 6, 7]\n",
      "Epoch 1/5\n",
      "129/129 [==============================] - 587s 5s/step - loss: 13.8410 - acc: 0.1395 - val_loss: 13.8155 - val_acc: 0.1429\n",
      "Epoch 2/5\n",
      "129/129 [==============================] - 581s 5s/step - loss: 13.7447 - acc: 0.1473 - val_loss: 13.8155 - val_acc: 0.1429\n",
      "Epoch 3/5\n",
      "129/129 [==============================] - 604s 5s/step - loss: 13.8273 - acc: 0.1421 - val_loss: 13.8155 - val_acc: 0.1429\n",
      "Epoch 4/5\n",
      "129/129 [==============================] - 585s 5s/step - loss: 13.8273 - acc: 0.1421 - val_loss: 13.8155 - val_acc: 0.1429\n",
      "Epoch 5/5\n",
      "129/129 [==============================] - 596s 5s/step - loss: 13.7447 - acc: 0.1473 - val_loss: 13.8155 - val_acc: 0.1429\n",
      "Epoch 6/10\n",
      "129/129 [==============================] - 593s 5s/step - loss: 13.8273 - acc: 0.1421 - val_loss: 13.8155 - val_acc: 0.1429\n",
      "Epoch 7/10\n",
      "129/129 [==============================] - 574s 4s/step - loss: 13.8273 - acc: 0.1421 - val_loss: 13.8155 - val_acc: 0.1429\n",
      "Epoch 8/10\n",
      "129/129 [==============================] - 554s 4s/step - loss: 13.8273 - acc: 0.1421 - val_loss: 13.8155 - val_acc: 0.1429\n",
      "Epoch 9/10\n",
      "129/129 [==============================] - 619s 5s/step - loss: 13.8273 - acc: 0.1421 - val_loss: 13.8155 - val_acc: 0.1429\n",
      "Epoch 10/10\n",
      "129/129 [==============================] - 971s 8s/step - loss: 13.8273 - acc: 0.1421 - val_loss: 13.8155 - val_acc: 0.1429\n",
      "Fine Classifier 1 Error: \n"
     ]
    }
   ],
   "source": [
    "#training fine classifiers on corresponding data\n",
    "for cat in range(coarse_categories):\n",
    "    index= 0\n",
    "    step = 5\n",
    "    stop = 30\n",
    "    \n",
    "    # Get all training data for the coarse category (not needed as we have generators)\n",
    "    ix = [i for i,j in f2cmap.items() if j==cat]\n",
    "    print(ix)\n",
    "    \n",
    "    while index < stop:\n",
    "        fine_models['models'][cat].fit_generator(traingenlist[cat],\n",
    "          epochs=index+step,\n",
    "          verbose=1, initial_epoch=index,\n",
    "          validation_data = valgenlist[cat]\n",
    "          )\n",
    "        index += step\n",
    "    \n",
    "    fine_models['models'][cat].compile(optimizer=sgd_fine, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    stop = 50\n",
    "\n",
    "    while index < stop:\n",
    "        fine_models['models'][cat].fit_generator(traingenlist[cat],\n",
    "          epochs=index+step,\n",
    "          verbose=1, initial_epoch=index,\n",
    "          validation_data = valgenlist[cat]\n",
    "          )\n",
    "        index += step\n",
    "        \n",
    "    #check: compilation needed??\n",
    "    \n",
    "    yh_f = fine_models['models'][cat].predict_generator(valgenlist[cat],steps=30)\n",
    "    print('Fine Classifier '+str(cat)+' Error: ')\n",
    "    #str(get_error(y_val[ix_v],yh_f)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yh_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probabilistic averaging\n",
    "#predictions from coarse classifier\n",
    "#coarse_predictions dim: n_images_predict X n_classes_coarse\n",
    "\n",
    "coarse_predictions=model_c.predict_generator(validation_generator,steps=30)\n",
    "#coarse_predictions=model_c.predict(img)\n",
    "#predictions from #(coarse categories) fine classifiers\n",
    "fine_predictions = [] #dim:  n_classes_coarse X n_images_predict X n_classes_fine\n",
    "for c in range(coarse_categories):\n",
    "    fine_predictions.append(fine_models['models'][c].predict_generator(validation_generator,steps=30))\n",
    "    #fine_predictions.append(fine_models['models'][c].predict(img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coarse_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32),\n",
       " array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], dtype=float32)]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_size = len(coarse_predictions)\n",
    "predictions = []\n",
    "for img in range(prediction_size):\n",
    "    proba = [0]*fine_categories\n",
    "    for finec in range(fine_categories):\n",
    "        for coarsec in range(coarse_categories):\n",
    "            proba[finec] += coarse_predictions[img][coarsec]*fine_predictions[coarsec][img][finec]\n",
    "    predicted = np.argmax(proba)\n",
    "    predictions.append(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
