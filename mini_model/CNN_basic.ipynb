{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import matplotlib.pylab as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg\n",
    "from sklearn.cluster import k_means\n",
    "from sklearn.cluster import *\n",
    "from imutils import paths\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "num_classes = 5\n",
    "epochs = 10\n",
    "imsize = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions\n",
    "img_x, img_y = imsize, imsize\n",
    "input_shape = (img_x, img_y,3)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading images...\")\n",
    "\n",
    "# grab the image paths and randomly shuffle them\n",
    "imagePaths = sorted(list(paths.list_images('data/train')))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "# loop over the input images\n",
    "labels = []\n",
    "data = []\n",
    "for imagePath in imagePaths:\n",
    "    # load the image, pre-process it, and store it in the data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    " \n",
    "    # extract the class label from the image path and update the\n",
    "    # labels list\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(label)\n",
    "\n",
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "    labels, test_size=0.25, random_state=42)\n",
    " \n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(labels)\n",
    "trainY1 = to_categorical(le.transform(trainY).flatten())\n",
    "testY1 = to_categorical(le.transform(testY).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 59 images belonging to 5 classes.\n",
      "Found 15 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',\n",
    "        target_size=(imsize, imsize),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/validation',\n",
    "        target_size=(imsize, imsize),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'110': 0, '12': 1, '140': 2, '260': 3, '7': 4}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int32"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_generator2.classes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_56 (Conv2D)           (None, 124, 124, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 58, 58, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 53824)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               5382500   \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 5,436,701\n",
      "Trainable params: 5,436,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 8s 424ms/step - loss: 1.6234 - acc: 0.2748 - val_loss: 1.5392 - val_acc: 0.2000\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 7s 359ms/step - loss: 1.4965 - acc: 0.3749 - val_loss: 1.5416 - val_acc: 0.4000\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 7s 362ms/step - loss: 1.4772 - acc: 0.3002 - val_loss: 1.3727 - val_acc: 0.3333\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 7s 363ms/step - loss: 1.2528 - acc: 0.5417 - val_loss: 1.3262 - val_acc: 0.4667\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 7s 362ms/step - loss: 1.2276 - acc: 0.4996 - val_loss: 1.5376 - val_acc: 0.2000\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 7s 358ms/step - loss: 1.1938 - acc: 0.5671 - val_loss: 1.3593 - val_acc: 0.4000\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 7s 357ms/step - loss: 0.9717 - acc: 0.6418 - val_loss: 1.2114 - val_acc: 0.4667\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 7s 363ms/step - loss: 0.7992 - acc: 0.7252 - val_loss: 1.2666 - val_acc: 0.6000\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 7s 362ms/step - loss: 0.5515 - acc: 0.8332 - val_loss: 1.6857 - val_acc: 0.3333\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 7s 354ms/step - loss: 0.7188 - acc: 0.8086 - val_loss: 0.9155 - val_acc: 0.5333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c585f96160>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=validation_generator,\n",
    "          )\n",
    "#model.fit(trainX, trainY1,batch_size=3,validation_data=(testX,testY1), epochs=epochs,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_generator.classes\n",
    "yval = validation_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = model.predict_generator(train_generator)\n",
    "yp = [np.argmax(x) for x in yp]\n",
    "ypval = model.predict_generator(validation_generator)\n",
    "ypval = [np.argmax(x) for x in ypval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([y,yp])\n",
    "df = df.transpose()\n",
    "df.columns =['t','p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(ftr):\n",
    "    print('compute softmax probabilities')\n",
    "    num, dim = ftr.shape[0], ftr.shape[1]\n",
    "    print('num %d dim %d' % (num, dim))\n",
    "    prob = np.zeros((num, dim), dtype=np.single)\n",
    "    for i in range(num):\n",
    "        max_val = np.max(ftr[i, :])\n",
    "        row = ftr[i, :] - max_val\n",
    "        exp_val = np.exp(row)\n",
    "        prob[i, :] = exp_val / np.sum(exp_val)\n",
    "    return prob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "num_values = 59\n",
    "root = 'C:/Users/Devanshi/Documents/CS259/Google-Landmark-Recognition-master/mini_model/'\n",
    "\n",
    "conf_mat = np.zeros((num_classes,num_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute softmax probabilities\n",
      "num 59 dim 5\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Hardcoding 100-class probabilities for validation images .\n",
    "'''\n",
    "class_prob = [14/59,16/59,5/59,14/59,10/59]\n",
    "val_prob = np.zeros((num_values,num_classes))\n",
    "\n",
    "for i in range(num_values):\n",
    "    for j in range(num_classes):\n",
    "        val_prob[i][j]=class_prob[j]\n",
    "val_prob=softmax(val_prob)\n",
    "#print(val_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(df.shape[0]):\n",
    "    t = df.loc[i]['t']\n",
    "    p = df.loc[i]['p']\n",
    "    #print(conf_mat)\n",
    "    conf_mat[t][p] =     conf_mat[t][p] +1\n",
    "    #print(conf_mat)\n",
    "for i in range(num_classes):\n",
    "    conf_mat[i] = conf_mat[i]/sum(conf_mat[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.6        0.2        0.         0.2       ]\n",
      " [0.125      0.5        0.0625     0.0625     0.25      ]\n",
      " [0.07142857 0.42857143 0.14285714 0.14285714 0.21428571]\n",
      " [0.2        0.1        0.1        0.3        0.3       ]\n",
      " [0.         0.21428571 0.28571429 0.28571429 0.21428571]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c5a68d4128>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(conf_mat)\n",
    "plt.imshow(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c5a68d4668>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist_mat = 1 - conf_mat\n",
    "dist_mat[range(num_classes),range(num_classes)]=0\n",
    "dist_mat = 0.5 * (dist_mat + dist_mat.T)\n",
    "plt.figure()\n",
    "plt.title('distance matrix on validation set')\n",
    "plt.imshow(dist_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4472136 -0.4472136 -0.4472136 -0.4472136 -0.4472136]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c5ad89d358>]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Laplacian eigenmap dimensionality reduction\n",
    "construct adjacency graph W (symmetric) using k-NN'''\n",
    "W=np.zeros((num_classes,num_classes))\n",
    "\n",
    "k_nn, t, dim = 2, 0.9, 4\n",
    "\n",
    "for i in range(num_classes):\n",
    "    idx=np.argsort(dist_mat[i,:])[1:k_nn+1]\n",
    "    W[i,idx]=np.exp(-dist_mat[i,idx] / t)\n",
    "    W[idx,i]=W[i,idx]\n",
    "D=np.zeros(W.shape)\n",
    "for i in range(num_classes):\n",
    "    D[i,i]=np.sum(W[i,:])\n",
    "L=D-W\n",
    "eig_val,eig_vec=scipy.linalg.eig(L,D)\n",
    "ftr=eig_vec[:,1:dim+1]\n",
    "print(eig_vec[:,0]) # the 1st eigenvector should be all ones\n",
    "eigval_cumsum = np.cumsum(np.real(eig_val))\n",
    "plt.plot(eigval_cumsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 clusters\n"
     ]
    }
   ],
   "source": [
    "affinity_propagation_cluster = AffinityPropagation(damping=0.75, max_iter=15000, convergence_iter=50, copy=True) \n",
    "cluster_labels = affinity_propagation_cluster.fit_predict(ftr)\n",
    "unique_cluster_label = np.unique(cluster_labels)\n",
    "n_cluster = unique_cluster_label.shape[0]\n",
    "cluster_members=[None]*n_cluster\n",
    "print ('%d clusters' % n_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 0 size 4 \n",
      "0,\n",
      "1,\n",
      "2,\n",
      "4,\n",
      " \n",
      "cluster 1 size 1 \n",
      "3,\n",
      " \n",
      "[[0, 1, 2, 4], [3]]\n"
     ]
    }
   ],
   "source": [
    "label_names=range(5)\n",
    "for i in range(n_cluster):\n",
    "    idx = np.nonzero(cluster_labels == unique_cluster_label[i])[0]\n",
    "    cluster_members[i]=list(idx)\n",
    "    print ('cluster %d size %d ' % (i, len(idx)))\n",
    "    for j in range(len(idx)):\n",
    "        print ('%s,' % label_names[idx[j]],)\n",
    "    print (' ')\n",
    "print(cluster_members)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2cmap = {}\n",
    "for coarse in range(len(cluster_members)):\n",
    "    for fine in cluster_members[coarse]:\n",
    "        f2cmap[fine] = coarse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 0, 2: 0, 3: 1, 4: 0}"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_fine = validation_generator.classes\n",
    "val_coarse = [f2cmap[c] for c in val_fine]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The number of coarse categories\n",
    "coarse_categories = n_cluster\n",
    "\n",
    "# The number of fine categories\n",
    "fine_categories = num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coarse_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fine2coarse = np.zeros((fine_categories,coarse_categories))\n",
    "for i in range(coarse_categories):\n",
    "    for j in cluster_members[i]:\n",
    "        fine2coarse[j,i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine2coarse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_coarse = []\n",
    "for i in df['t']:\n",
    "    train_coarse.append(cluster_labels[i])\n",
    "#df['coarse'] = train_coarse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>p</th>\n",
       "      <th>coarse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   t  p  coarse\n",
       "0  0  4       0\n",
       "1  0  1       0\n",
       "2  0  2       0\n",
       "3  0  1       0\n",
       "4  0  1       0"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#single classifier (shared)\n",
    "from keras import optimizers\n",
    "from keras.layers import Input, Conv2D, Dropout, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "in_layer = Input(shape=(128, 128, 3), dtype='float32', name='main_input')\n",
    "\n",
    "net = Conv2D(384, 3, strides=1, padding='same', activation='elu')(in_layer)\n",
    "net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "\n",
    "net = Conv2D(384, 1, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(384, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(640, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(640, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Dropout(.2)(net)\n",
    "net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "\n",
    "net = Conv2D(640, 1, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(768, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(768, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(768, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Dropout(.3)(net)\n",
    "net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "\n",
    "net = Conv2D(768, 1, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(896, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(896, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Dropout(.4)(net)\n",
    "net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "\n",
    "net = Conv2D(896, 3, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(1024, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(1024, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Dropout(.5)(net)\n",
    "net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "\n",
    "net = Conv2D(1024, 1, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(1152, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Dropout(.6)(net)\n",
    "net = MaxPooling2D((2, 2), padding='same')(net)\n",
    "\n",
    "net = Flatten()(net)\n",
    "net = Dense(1152, activation='elu')(net)\n",
    "net = Dense(fine_categories, activation='softmax')(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=in_layer,outputs=net)\n",
    "sgd_coarse = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer= sgd_coarse, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "20/20 [==============================] - 418s 21s/step - loss: 11.0954 - acc: 0.2248 - val_loss: 12.4679 - val_acc: 0.2000\n"
     ]
    }
   ],
   "source": [
    "batch = 64\n",
    "index= 0\n",
    "step = 1\n",
    "stop = 1\n",
    "\n",
    "while index < stop:\n",
    "    model.fit_generator(train_generator,\n",
    "          epochs=index+step,\n",
    "          verbose=1, initial_epoch=index,\n",
    "          validation_data=validation_generator,\n",
    "          )\n",
    "    #model.fit_generator(train_generator, batch_size=batch, initial_epoch=index, epochs=index+step,\n",
    "    index += step\n",
    "    model.save_weights('data/models/model_coarse'+str(index))\n",
    "save_index = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_fine = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(model.layers)):\n",
    "    model.layers[i].trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = Conv2D(1024, 1, strides=1, padding='same', activation='elu')(model.layers[-8].output)\n",
    "net = Conv2D(1152, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Dropout(.6)(net)\n",
    "net = MaxPooling2D((2, 2), padding='same')(net)\n",
    "\n",
    "net = Flatten()(net)\n",
    "net = Dense(1152, activation='elu')(net)\n",
    "out_coarse = Dense(coarse_categories, activation='softmax')(net)\n",
    "\n",
    "model_c = Model(inputs=in_layer,outputs=out_coarse)\n",
    "model_c.compile(optimizer= sgd_coarse, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "for i in range(len(model_c.layers)-1):\n",
    "    model_c.layers[i].set_weights(model.layers[i].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "main_input (InputLayer)      (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_93 (Conv2D)           (None, 128, 128, 384)     10752     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 64, 64, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 64, 64, 384)       147840    \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 64, 64, 384)       590208    \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 64, 64, 640)       983680    \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 64, 64, 640)       1639040   \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 64, 64, 640)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 32, 32, 640)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 32, 32, 640)       410240    \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 32, 32, 768)       1966848   \n",
      "_________________________________________________________________\n",
      "conv2d_100 (Conv2D)          (None, 32, 32, 768)       2360064   \n",
      "_________________________________________________________________\n",
      "conv2d_101 (Conv2D)          (None, 32, 32, 768)       2360064   \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 32, 32, 768)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 16, 16, 768)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_102 (Conv2D)          (None, 16, 16, 768)       590592    \n",
      "_________________________________________________________________\n",
      "conv2d_103 (Conv2D)          (None, 16, 16, 896)       2753408   \n",
      "_________________________________________________________________\n",
      "conv2d_104 (Conv2D)          (None, 16, 16, 896)       3212160   \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 16, 16, 896)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 8, 8, 896)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_105 (Conv2D)          (None, 8, 8, 896)         7226240   \n",
      "_________________________________________________________________\n",
      "conv2d_106 (Conv2D)          (None, 8, 8, 1024)        3671040   \n",
      "_________________________________________________________________\n",
      "conv2d_107 (Conv2D)          (None, 8, 8, 1024)        4195328   \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 8, 8, 1024)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_112 (Conv2D)          (None, 4, 4, 1024)        1049600   \n",
      "_________________________________________________________________\n",
      "conv2d_113 (Conv2D)          (None, 4, 4, 1152)        4719744   \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 4, 4, 1152)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 2, 2, 1152)        0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1152)              5309568   \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 2)                 2306      \n",
      "=================================================================\n",
      "Total params: 43,198,722\n",
      "Trainable params: 11,081,218\n",
      "Non-trainable params: 32,117,504\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_c.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg_copy =copy.copy(train_generator)\n",
    "val_copy = copy.copy(validation_generator)\n",
    "# trg_fc = trg_copy.classes\n",
    "val_fc = val_copy.classes\n",
    "trg_copy.classes = np.array([f2cmap[f] for f in trg_fc])\n",
    "val_copy.classes = np.array([f2cmap[f] for f in val_fc])\n",
    "#trg_copy.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# print(train_generator.class_indices)\n",
    "\n",
    "# directory = root+\"/data/\"\n",
    "# src = root+\"/data/train/\"\n",
    "# for c in range(coarse_categories):\n",
    "#     if not os.path.exists(directory+\"/\"+str(c)):\n",
    "#         os.makedirs(directory+\"/\"+str(c))\n",
    "\n",
    "# for key,value in train_generator.class_indices:\n",
    "#     c = f2cmap[value]\n",
    "    \n",
    "#     #TODO\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp C:/Users/Devanshi/Documents/CS259/Google-Landmark-Recognition-master/mini_model//data/train/140/*.* C:/Users/Devanshi/Documents/CS259/Google-Landmark-Recognition-master/mini_model//data//0/\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "#shutil.copy2(src+\"140\",directory+\"/0\")\n",
    "os.system('xcopy '+ src+\"140/*\" +\" \"+ directory+\"/0/\")\n",
    "print('cp '+ src+\"140/*.*\" +\" \"+ directory+\"/0/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 59 images belonging to 2 classes.\n",
      "Found 15 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator2 = train_datagen.flow_from_directory(\n",
    "        'data/train3',\n",
    "        target_size=(imsize, imsize),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "validation_generator2 = test_datagen.flow_from_directory(\n",
    "        'data/validation3',\n",
    "        target_size=(imsize, imsize),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator2.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3\n",
      "20/20 [==============================] - 166s 8s/step - loss: 3.7576 - acc: 0.7665 - val_loss: 3.2236 - val_acc: 0.8000\n"
     ]
    }
   ],
   "source": [
    "index = 2\n",
    "step = 1\n",
    "stop = 3\n",
    "\n",
    "while index < stop:\n",
    "    #model_c.fit(x_train, y_train_c, batch_size=batch, initial_epoch=index, epochs=index+step, validation_data=(x_val, y_val_c), callbacks=[tbCallBack])\n",
    "    model_c.fit_generator(train_generator2,\n",
    "          epochs=index+step,\n",
    "          verbose=1, initial_epoch=index,\n",
    "          validation_data = validation_generator2\n",
    "          )\n",
    "    index += step"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y,yval, yp,ypval, val_coarse,val_fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fine_model(nfine):\n",
    "    net = Conv2D(1024, 1, strides=1, padding='same', activation='elu')(model.layers[-8].output)\n",
    "    net = Conv2D(1152, 2, strides=1, padding='same', activation='elu')(net)\n",
    "    net = Dropout(.6)(net)\n",
    "    net = MaxPooling2D((2, 2), padding='same')(net)\n",
    "\n",
    "    net = Flatten()(net)\n",
    "    net = Dense(1152, activation='elu')(net)\n",
    "    out_fine = Dense(nfine, activation='softmax')(net)\n",
    "    model_fine = Model(inputs=in_layer,outputs=out_fine)\n",
    "    model_fine.compile(optimizer= sgd_coarse,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    for i in range(len(model_fine.layers)-1):\n",
    "        model_fine.layers[i].set_weights(model.layers[i].get_weights())\n",
    "    return model_fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fine_models = {'models' : [{} for i in range(coarse_categories)], 'yhf' : [{} for i in range(coarse_categories)]}\n",
    "for i in range(coarse_categories):\n",
    "    model_i = fine_model(len(cluster_members[i]))\n",
    "    fine_models['models'][i] = model_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_error(y,yh):\n",
    "    # Threshold \n",
    "    yht = np.zeros(np.shape(yh))\n",
    "    yht[np.arange(len(yh)), yh.argmax(1)] = 1\n",
    "    # Evaluate Error\n",
    "    error = np.count_nonzero(np.count_nonzero(y-yht,1))/len(y)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 49 images belonging to 4 classes.\n",
      "Found 12 images belonging to 4 classes.\n",
      "Found 10 images belonging to 1 classes.\n",
      "Found 3 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "traingenlist = []\n",
    "valgenlist = []\n",
    "for i in range(coarse_categories):\n",
    "    tgen = train_datagen.flow_from_directory(\n",
    "            'data/train3/'+str(i),\n",
    "            target_size=(imsize, imsize),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "    vgen = test_datagen.flow_from_directory(\n",
    "            'data/validation3/'+str(i),\n",
    "            target_size=(imsize, imsize),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "    traingenlist.append(tgen)\n",
    "    valgenlist.append(vgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 4]\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 138s 8s/step - loss: 11.0865 - acc: 0.3122 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 2/2\n",
      "17/17 [==============================] - 135s 8s/step - loss: 11.0865 - acc: 0.3122 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 3/3\n",
      "17/17 [==============================] - 133s 8s/step - loss: 11.6835 - acc: 0.2751 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 4/4\n",
      "14/17 [=======================>......] - ETA: 19s - loss: 12.2805 - acc: 0.2381"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-285-d67c334b06f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m           \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalgenlist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m           )\n\u001b[0;32m     28\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2228\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2229\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2230\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2232\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1883\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1885\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2482\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2483\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for cat in range(coarse_categories):\n",
    "    index= 0\n",
    "    step = 1\n",
    "    stop = 2\n",
    "    \n",
    "    # Get all training data for the coarse category\n",
    "    #ix = np.where([(y[:,j]==1) for j in [k for k, e in enumerate(fine2coarse[:,i]) if e != 0]])[1]\n",
    "    ix = [i for i,j in f2cmap.items() if j==cat]\n",
    "    print(ix)\n",
    "    \n",
    "    while index < stop:\n",
    "        fine_models['models'][cat].fit_generator(traingenlist[cat],\n",
    "          epochs=index+step,\n",
    "          verbose=1, initial_epoch=index,\n",
    "          validation_data = valgenlist[cat]\n",
    "          )\n",
    "        index += step\n",
    "    \n",
    "    fine_models['models'][cat].compile(optimizer=sgd_fine, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    stop = 10\n",
    "\n",
    "    while index < stop:\n",
    "        fine_models['models'][cat].fit_generator(traingenlist[cat],\n",
    "          epochs=index+step,\n",
    "          verbose=1, initial_epoch=index,\n",
    "          validation_data = valgenlist[cat]\n",
    "          )\n",
    "        index += step\n",
    "        \n",
    "    yh_f = fine_models['models'][cat].predict_generator(valgenlist[cat])\n",
    "    print('Fine Classifier '+str(cat)+' Error: ')\n",
    "    #str(get_error(y_val[ix_v],yh_f)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##predictions from model_c.predict\n",
    "coarse_predictions = [] # dim: n_images_predict X n_classes_coarse\n",
    "##predictions from <n_classes_course> fine classifiers\n",
    "fine_predictions = [] #dim:  n_classes_coarse X n_images_predict X n_classes_fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-2-63dbba779b70>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-63dbba779b70>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "prection_size = len(images_predict)\n",
    "predictions = []\n",
    "for img in range(prection_size):\n",
    "    proba = [0]*n_classes_fine\n",
    "    for finec in range(n_classes_fine):\n",
    "        for coarsec in range(n_classes_course):\n",
    "            proba[finec] += coarse_predictions[img][coa]*fine_predictions[coarsec][img][finec]\n",
    "    predicted = np.argmax(proba)\n",
    "    predictions.append(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
