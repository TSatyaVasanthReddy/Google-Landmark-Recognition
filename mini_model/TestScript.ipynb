{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Devanshi\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 3)\n",
      "Found 15 images belonging to 5 classes.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'modeldir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-94b7f3a93ec6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0min_layer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodeldir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"simplemodel_wt.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Loaded simple model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'modeldir' is not defined"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.layers import Input, Conv2D, Dropout, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "from keras.models import model_from_json\n",
    "import scipy.linalg\n",
    "from sklearn.cluster import k_means\n",
    "from sklearn.cluster import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "\n",
    "\n",
    "modeldir = \"data/models/\"\n",
    "num_classes = 5\n",
    "#MODIFY or ADD from cmd\n",
    "coarse_categories = 3\n",
    "fine_categories = num_classes\n",
    "\n",
    "batch_size = 128\n",
    "imsize = 128\n",
    "\n",
    "# input image dimensions\n",
    "img_x, img_y = imsize, imsize\n",
    "input_shape = (img_x, img_y,3)\n",
    "print(input_shape)\n",
    "\n",
    "#ImageDataGenerator to generate batches of images\n",
    "#add: zca_whitening = True,\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'data/validation',\n",
    "        target_size=(imsize, imsize),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "#single classifier training (shared)\n",
    "in_layer = Input(shape=input_shape, dtype='float32', name='main_input')\n",
    "\n",
    "net = Conv2D(184, 3, strides=1, padding='same', activation='elu')(in_layer)\n",
    "net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "\n",
    "net = Conv2D(184, 1, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(184, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(284, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(284, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Dropout(.2)(net)\n",
    "net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "\n",
    "net = Conv2D(284, 1, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(440, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(440, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Dropout(.4)(net)\n",
    "net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "\n",
    "net = Conv2D(440, 3, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(568, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(568, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Dropout(.5)(net)\n",
    "net = MaxPooling2D((2, 2), padding='valid')(net)\n",
    "\n",
    "net = Conv2D(568, 1, strides=1, padding='same', activation='elu')(net)\n",
    "net = Conv2D(606, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Dropout(.6)(net)\n",
    "net = MaxPooling2D((2, 2), padding='same')(net)\n",
    "\n",
    "net = Flatten()(net)\n",
    "net = Dense(606, activation='elu')(net)\n",
    "net = Dense(fine_categories, activation='softmax')(net)\n",
    "\n",
    "\n",
    "model = Model(inputs=in_layer,outputs=net)\n",
    "\n",
    "model.load_weights(modeldir+\"simplemodel_wt.h5\")\n",
    "print(\"Loaded simple model\")\n",
    "\n",
    "#fine-tuning for coarse classifier\n",
    "net = Conv2D(568, 1, strides=1, padding='same', activation='elu')(model.layers[-8].output)\n",
    "net = Conv2D(606, 2, strides=1, padding='same', activation='elu')(net)\n",
    "net = Dropout(.6)(net)\n",
    "net = MaxPooling2D((2, 2), padding='same')(net)\n",
    "\n",
    "net = Flatten()(net)\n",
    "net = Dense(606, activation='elu')(net)\n",
    "out_coarse = Dense(coarse_categories, activation='softmax')(net)\n",
    "\n",
    "model_c = Model(inputs=in_layer,outputs=out_coarse)\n",
    "\n",
    "for i in range(len(model_c.layers)-1):\n",
    "    model_c.layers[i].set_weights(model.layers[i].get_weights())\n",
    "\n",
    "model_c.load_weights(modeldir+\"coarsemodel_wt.h5\")\n",
    "print(\"Loaded coarse model\")\n",
    "\n",
    "#constructing fine classifiers\n",
    "def fine_model():\n",
    "    net = Conv2D(568, 1, strides=1, padding='same', activation='elu')(model.layers[-8].output)\n",
    "    net = Conv2D(606, 2, strides=1, padding='same', activation='elu')(net)\n",
    "    net = Dropout(.6)(net)\n",
    "    net = MaxPooling2D((2, 2), padding='same')(net)\n",
    "\n",
    "    net = Flatten()(net)\n",
    "    net = Dense(606, activation='elu')(net)\n",
    "    out_fine = Dense(fine_categories, activation='softmax')(net)\n",
    "    model_fine = Model(inputs=in_layer,outputs=out_fine)\n",
    "    \n",
    "\n",
    "    for i in range(len(model_fine.layers)-1):\n",
    "        model_fine.layers[i].set_weights(model.layers[i].get_weights())\n",
    "    return model_fine\n",
    "\n",
    "fine_models = {'models' : [{} for i in range(coarse_categories)], 'yhf' : [{} for i in range(coarse_categories)]}\n",
    "for i in range(coarse_categories):\n",
    "    model_i = fine_model()\n",
    "    fine_models['models'][i] = model_i\n",
    "\n",
    "\n",
    "# In[81]:\n",
    "\n",
    "\n",
    "#training fine classifiers on corresponding data\n",
    "for cat in range(coarse_categories):\n",
    "    fine_models['models'][cat].load_weights(modeldir+str(cat)+\"finemodel_wt.h5\")\n",
    "    \n",
    "print(\"Loaded fine models\")\n",
    "\n",
    "#MODIFY to get accuracy\n",
    "def get_error(t,p):\n",
    "    #TODO add confidence score\n",
    "    return accuracy_score(t,p)\n",
    "\n",
    "#predicting\n",
    "coarse_predictions=model_c.predict_generator(test_generator)\n",
    "#predictions from #(coarse categories) fine classifiers\n",
    "fine_predictions = []    #dim:  n_classes_coarse X n_images_predict X n_classes_fine\n",
    "for c in range(coarse_categories):\n",
    "    fine_predictions.append(fine_models['models'][c].predict_generator(test_generator))\n",
    "\n",
    "print(\"Got predictions\")\n",
    "\n",
    "prediction_size = len(coarse_predictions)\n",
    "predictions = []\n",
    "for img in range(prediction_size):\n",
    "    proba = [0]*fine_categories\n",
    "    for finec in range(fine_categories):\n",
    "        for coarsec in range(coarse_categories):\n",
    "            proba[finec] += coarse_predictions[img][coarsec]*fine_predictions[coarsec][img][finec]\n",
    "    predicted = np.argmax(proba)\n",
    "    predictions.append(predicted)\n",
    "\n",
    "truelabels = test_generator.classes\n",
    "\n",
    "get_error(truelabels,predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_error(truelabels,predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
